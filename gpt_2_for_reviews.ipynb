{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt_2_for_reviews.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u6MjGQAuzWN",
        "colab_type": "text"
      },
      "source": [
        "# Sample Steam Reviews with GPT-2\n",
        "Code inspired from https://github.com/woctezuma/sample-steam-reviews-with-gpt-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KjP9yVVveN1",
        "colab_type": "text"
      },
      "source": [
        "## Setting the GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A1zEYHxh304_"
      },
      "source": [
        "Install the Python package\n",
        "\n",
        "Reference: https://github.com/minimaxir/gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ruwgwCuEHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gpt_2_simple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkq7wEQwEkZ",
        "colab_type": "text"
      },
      "source": [
        "Download the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pdkhHU6wd12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ggC2Mc75BnB",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r3939YUqT9K",
        "colab_type": "text"
      },
      "source": [
        "Choose between `117M` and `345M` models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW4vZzlyqOnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_name = '117M'\n",
        "model_name = '345M'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_hrBy2DqR5M",
        "colab_type": "text"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-If30nT4ZCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9sI2rah5OyB",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r82T8yOm8jyL",
        "colab_type": "text"
      },
      "source": [
        "### Either get the data by yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsEEvL5b8IDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/woctezuma/sample-steam-reviews-with-gpt-2/master/export_review_data.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJLNxAhg8IQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/woctezuma/sample-steam-reviews-with-gpt-2/master/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMhEG1Xi8UZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWekXOQGBD1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app_id = 583950 # Artifact: 583950\n",
        "\n",
        "num_days = 28*3 # slightly less than 3 months\n",
        "# num_days = -1 # if negative, then no time limit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9sMp0WC8aP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from export_review_data import apply_workflow_for_app_id\n",
        "\n",
        "apply_workflow_for_app_id(app_id,\n",
        "                          num_days=num_days)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LPbkB998g-B",
        "colab_type": "text"
      },
      "source": [
        "### Or get a data snapshot from me\n",
        "\n",
        "Currently only possible for Artifact, as an example, because the recommended way is to run the code above for the game of your choice instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIR9fBid5U2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data/\n",
        "\n",
        "## Either Artifact (only the recent English reviews):\n",
        "# !curl -O https://raw.githubusercontent.com/woctezuma/sample-steam-reviews-with-gpt-2/master/data/with_delimiters/583950.txt\n",
        "# !mv 583950.txt data/\n",
        "\n",
        "## Or Crusader Kings II (all the English reviews):\n",
        "# !curl -O https://raw.githubusercontent.com/wiki/woctezuma/sample-steam-reviews-with-gpt-2/data/with_delimiters/203770.txt\n",
        "# !mv 203770.txt data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjmpOgoa5y7Q",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu5ctG0DBLIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = 'data/' + str(app_id) + '.txt'\n",
        "\n",
        "run_name = model_name + '_reviews_' + str(app_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bfg4HYZl56JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              run_name=run_name,\n",
        "              dataset=file_name,\n",
        "              model_name=model_name,\n",
        "              steps=1000,\n",
        "              restore_from='fresh', # change to 'latest' to resume training\n",
        "              print_every=10,       # how many steps between printing progress\n",
        "              sample_every=200,     # how many steps to print a demo sample\n",
        "              save_every=500        # how many steps between saving checkpoint              \n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BK1U2dRuR6I",
        "colab_type": "text"
      },
      "source": [
        "## Save a Trained Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csfQ7zoi5gWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XheLKHQYePP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.copy_checkpoint_to_gdrive(run_name=run_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buHDxtUIfikS",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shTR7bzRgTkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy9od04seNhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpt2.copy_checkpoint_from_gdrive(run_name=run_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX8KFoKR6g-o",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2RBA9hMIFlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature=1.0 # Default is 0.7, but you may want to increase the temperature, especially if your dataset is small, to avoid copying text.\n",
        "top_k = 40      # Default: 0   ; Recommended: 40  ; useless parameter if top_p > 0.0\n",
        "top_p = 0.9     # Default: 0.0 ; Recommended: 0.9 ; no need for top_k if top_p > 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_C_i_q7hZ8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_samples = 3\n",
        "num_batches = 3 # Unique to GPT-2, you can pass a batch_size to generate multiple samples in parallel, giving a massive speedup."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYC30GEi6kPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_texts_A = gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,              \n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,\n",
        "              return_as_list=True)\n",
        "\n",
        "print('\\n\\n--- SEPARATOR ---\\n\\n'.join(gen_texts_A))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrZBWas662k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_texts_B = gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='<|startoftext|>I love',\n",
        "              truncate='<|endoftext|>',\n",
        "              return_as_list=True)\n",
        "\n",
        "print('\\n\\n--- SEPARATOR ---\\n\\n'.join(gen_texts_B))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEAeBOlS7eCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_texts_C = gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='<|startoftext|>I hate',\n",
        "              truncate='<|endoftext|>',\n",
        "              return_as_list=True)\n",
        "\n",
        "print('\\n\\n--- SEPARATOR ---\\n\\n'.join(gen_texts_C))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX8KxDY27hJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_texts_D = gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='<|startoftext|>Please',\n",
        "              truncate='<|endoftext|>',\n",
        "              return_as_list=True)\n",
        "\n",
        "print('\\n\\n--- SEPARATOR ---\\n\\n'.join(gen_texts_D))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppNhFzjPIVZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_texts_E = gpt2.generate(sess,\n",
        "              run_name=run_name,\n",
        "              nsamples=num_samples,\n",
        "              batch_size=num_batches,\n",
        "              temperature=temperature,\n",
        "              top_k=top_k,\n",
        "              top_p=top_p,                            \n",
        "              prefix='<|startoftext|>This game has near infinite replay value',\n",
        "              truncate='<|endoftext|>',\n",
        "              return_as_list=True)\n",
        "\n",
        "print('\\n\\n--- SEPARATOR ---\\n\\n'.join(gen_texts_E))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMlAC87jkZkx",
        "colab_type": "text"
      },
      "source": [
        "## Copy the Generated Text to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyL0qToNjhG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temperature_suffixe = '_temperature_' + str(temperature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1W36OQxgkj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if top_p > 0.0:\n",
        "  file_name_suffixe = temperature_suffixe + '_top_p_' + str(top_p)\n",
        "elif top_k > 0:\n",
        "  file_name_suffixe = temperature_suffixe + '_top_k_' + str(top_k)\n",
        "else:\n",
        "  file_name_suffixe = temperature_suffixe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkjbmwyxeqEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_file_name = 'output_' + str(app_id) + file_name_suffixe + '.md'\n",
        "\n",
        "print(output_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joHIx0aaYVKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(output_file_name, 'w') as f:\n",
        "  \n",
        "  f.write('## Game\\n\\n')\n",
        "  f.write('[<img alt=\"game name\" src=\"https://steamcdn-a.akamaihd.net/steam/apps/{}/header.jpg\" width=\"150\">](https://store.steampowered.com/app/{})\\n\\n'.format(app_id, app_id))\n",
        "  \n",
        "  f.write('## Reviews generated unconditionally\\n\\n')\n",
        "  for (i, gen_text) in enumerate(gen_texts_A):\n",
        "    f.write('{}.\\n\\n'.format(i+1))\n",
        "    f.write('> {}\\n\\n'.format(gen_text))\n",
        "    \n",
        "  f.write('## Reviews starting with I love\\n\\n')\n",
        "  for (i, gen_text) in enumerate(gen_texts_B):\n",
        "    f.write('{}.\\n\\n'.format(i+1))\n",
        "    f.write('> {}\\n\\n'.format(gen_text))\n",
        "    \n",
        "  f.write('## Reviews starting with I hate\\n\\n')    \n",
        "  for (i, gen_text) in enumerate(gen_texts_C):\n",
        "    f.write('{}.\\n\\n'.format(i+1))\n",
        "    f.write('> {}\\n\\n'.format(gen_text))\n",
        "  \n",
        "  f.write('## Reviews starting with Please\\n\\n')  \n",
        "  for (i, gen_text) in enumerate(gen_texts_D):\n",
        "    f.write('{}.\\n\\n'.format(i+1))\n",
        "    f.write('> {}\\n\\n'.format(gen_text))\n",
        "  \n",
        "  f.write('## Reviews starting with This game has near infinite replay value\\n\\n')  \n",
        "  for (i, gen_text) in enumerate(gen_texts_E):\n",
        "    f.write('{}.\\n\\n'.format(i+1))\n",
        "    f.write('> {}\\n\\n'.format(gen_text))\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcLRTVI1bBon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTsKdSSIajwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copyfile(output_file_name, '/content/drive/My Drive/' + output_file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}